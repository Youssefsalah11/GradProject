{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7119431,"sourceType":"datasetVersion","datasetId":4106164},{"sourceId":7119508,"sourceType":"datasetVersion","datasetId":4106212}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-15T18:53:30.887313Z","iopub.execute_input":"2023-12-15T18:53:30.888044Z","iopub.status.idle":"2023-12-15T18:53:31.291747Z","shell.execute_reply.started":"2023-12-15T18:53:30.888008Z","shell.execute_reply":"2023-12-15T18:53:31.290477Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/trained-model-pth/trained_model.pth\n/kaggle/input/images/04950.jpg\n/kaggle/input/images/02610.jpg\n","output_type":"stream"}]},{"cell_type":"code","source":"from fastai.vision.all import *\nimport os\nimport csv\nimport pandas as pd\nfrom torchvision.io import read_image\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor\nimport torch\nfrom torch.utils.data import DataLoader\n!pip install torch torchvision segmentation-models-pytorch\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:53:42.569211Z","iopub.execute_input":"2023-12-15T18:53:42.569749Z","iopub.status.idle":"2023-12-15T18:54:11.098660Z","shell.execute_reply.started":"2023-12-15T18:53:42.569704Z","shell.execute_reply":"2023-12-15T18:54:11.097472Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nCollecting segmentation-models-pytorch\n  Obtaining dependency information for segmentation-models-pytorch from https://files.pythonhosted.org/packages/cb/70/4aac1b240b399b108ce58029ae54bc14497e1bbc275dfab8fd3c84c1e35d/segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.1.0)\nCollecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting timm==0.9.2 (from segmentation-models-pytorch)\n  Obtaining dependency information for timm==0.9.2 from https://files.pythonhosted.org/packages/29/90/94f5deb8d76e24a89813aef95e8809ca8fd7414490428480eda19b133d4a/timm-0.9.2-py3-none-any.whl.metadata\n  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n  Obtaining dependency information for munch from https://files.pythonhosted.org/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl.metadata\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.17.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.10.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\nDownloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=56562e23662777a057836f285fc47afcdd12e99999252173881996070d032818\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=08c7a64508f651e8f81c4e8ed1a86fed623719df1869c83703c8773bccab1a5b\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 0.9.10\n    Uninstalling timm-0.9.10:\n      Successfully uninstalled timm-0.9.10\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Replace 'path_to_your_npy_file.npy' with the actual file path\narray = np.load('/kaggle/working/images.npy')\n\n# Now you can use 'array' as a normal NumPy array\nprint(array.shape)\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:08:02.747330Z","iopub.execute_input":"2023-12-15T19:08:02.747740Z","iopub.status.idle":"2023-12-15T19:08:02.932416Z","shell.execute_reply.started":"2023-12-15T19:08:02.747705Z","shell.execute_reply":"2023-12-15T19:08:02.931421Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"(14999, 80, 160, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#  Dataset","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom PIL import Image\nfrom torchvision.transforms import Resize, ToTensor, Compose\nfrom torch.utils.data import Dataset\nimport torch\n\nclass LaneDetectionDataset(Dataset):\n    def __init__(self, images_npy, labels_npy, img_transform=None, label_transform=None):\n        # Load image and label data from separate .npy files\n        self.images = np.load(images_npy, allow_pickle=True)\n        self.labels = np.load(labels_npy, allow_pickle=True)\n        self.img_transform = img_transform\n        self.label_transform = label_transform\n\n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        # Retrieve image and label arrays\n        image_arr = self.images[idx]\n        label_arr = self.labels[idx]\n\n        # Convert numpy arrays to PIL images\n        image = Image.fromarray(image_arr)\n\n        # Convert label to grayscale PIL Image\n        label = Image.fromarray(label_arr).convert('L') \n\n        # Apply transformations\n        if self.img_transform:\n            image = self.img_transform(image)\n        if self.label_transform:\n            label = self.label_transform(label)\n\n        return image, label\n\n\n\nlabel_transform = img_transform = Compose([\n    Resize((96, 160)),\n    ToTensor()\n])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:41:03.037861Z","iopub.execute_input":"2023-12-13T17:41:03.038613Z","iopub.status.idle":"2023-12-13T17:41:03.050677Z","shell.execute_reply.started":"2023-12-13T17:41:03.038579Z","shell.execute_reply":"2023-12-13T17:41:03.048640Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Spliting Data","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Load the images and labels from their respective files\nimages = np.load('/kaggle/working/images.npy', allow_pickle=True)\nlabels = np.load('/kaggle/working/labels.npy', allow_pickle=True)\n\n\nimages_train, images_val, labels_train, labels_val = train_test_split(\n    images, labels, test_size=0.2, random_state=42)\n\n# Save the split datasets to new .npy files\nnp.save('images_train.npy', images_train)\nnp.save('images_val.npy', images_val)\nnp.save('labels_train.npy', labels_train)\nnp.save('labels_val.npy', labels_val)\n\nprint(\"Training and validation sets have been created and saved.\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:39:27.653595Z","iopub.execute_input":"2023-12-13T17:39:27.653979Z","iopub.status.idle":"2023-12-13T17:39:28.672955Z","shell.execute_reply.started":"2023-12-13T17:39:27.653947Z","shell.execute_reply":"2023-12-13T17:39:28.672024Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Training and validation sets have been created and saved.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Finding The Best Learning Rate","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport segmentation_models_pytorch as smp\n# Assuming 'model', 'train_loader', and 'criterion' are already defined\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = smp.Unet(\n            encoder_name=\"resnet50\",    # Use MobileNetV2 as encoder\n            encoder_weights=\"imagenet\",     # Pre-trained weights on ImageNet\n            in_channels=3,                  # Number of input channels\n            classes=1,                      # Number of output classes (binary mask)\n        ).to(device)\n\n\n\ntrain_dataset = LaneDetectionDataset('/kaggle/working/images_train.npy', '/kaggle/working/labels_train.npy', img_transform=img_transform, label_transform=label_transform)\nval_dataset = LaneDetectionDataset('/kaggle/working/images_val.npy', '/kaggle/working/labels_val.npy', img_transform=img_transform, label_transform=label_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\ncriterion =  nn.BCEWithLogitsLoss()  \n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)  # Start with a small LR\n\n# Initialize variables\nlr_find_epochs = 2\nlr_multiplier = (1e-1 / 1e-4) ** (1 / (lr_find_epochs * len(train_loader)))\ncurrent_lr = 1e-4\nlrs = []\nlosses = []\n\nmodel.train()\nfor epoch in range(lr_find_epochs):\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        # Update LR\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = current_lr\n        current_lr *= lr_multiplier\n        \n\n        inputs=inputs.to(device)\n        targets=targets.to(device)\n        \n        # Training step\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        # Record LR and loss\n        lrs.append(optimizer.param_groups[0]['lr'])\n        losses.append(loss.item())\n\n# Plotting\nplt.plot(lrs, losses)\nplt.xscale('log')  # Use logarithmic scale for x-axis\nplt.xlabel('Learning Rate')\nplt.ylabel('Loss')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:41:06.929605Z","iopub.execute_input":"2023-12-13T17:41:06.930490Z","iopub.status.idle":"2023-12-13T17:42:44.392517Z","shell.execute_reply.started":"2023-12-13T17:41:06.930429Z","shell.execute_reply":"2023-12-13T17:42:44.390790Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"lrs[losses.index(min(losses))]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:44:45.362114Z","iopub.execute_input":"2023-12-13T17:44:45.362555Z","iopub.status.idle":"2023-12-13T17:44:45.368593Z","shell.execute_reply.started":"2023-12-13T17:44:45.362521Z","shell.execute_reply":"2023-12-13T17:44:45.367675Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0.004737311198598112"},"metadata":{}}]},{"cell_type":"markdown","source":"# Finding the best batch size","metadata":{}},{"cell_type":"markdown","source":"# Training ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nimport segmentation_models_pytorch as smp\n\n\n\n\n# Define device: Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ntrain_dataset = LaneDetectionDataset('/kaggle/working/images_train.npy', '/kaggle/working/labels_train.npy', img_transform=img_transform, label_transform=label_transform,)\nval_dataset = LaneDetectionDataset('/kaggle/working/images_val.npy', '/kaggle/working/labels_val.npy', img_transform=img_transform, label_transform=label_transform , )\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n\n# # Initialize a U-Net model with a MobileNet encoder\nmodel = smp.Unet(\n    encoder_name=\"resnet50\",    # Use MobileNetV2 as encoder\n    encoder_weights=\"imagenet\",     # Pre-trained weights on ImageNet\n    in_channels=3,                  # Number of input channels\n    classes=1,                      # Number of output classes (binary mask)\n).to(device)\n\n\n\ncriterion = nn.BCEWithLogitsLoss()  \noptimizer = optim.Adam(model.parameters(), lr=lrs[losses.index(min(losses))])\n\n# Training loop\nnum_epochs = 15  # Set this to a suitable value\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    \n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Forward pass\n        outputs = model(images)  # Get raw logits from the model\n        loss = criterion(outputs, labels)  # Calculate loss with raw logits\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * images.size(0)\n\n    epoch_loss = running_loss / len(train_loader.dataset)\n    torch.save(model.state_dict(), f\"{epoch+1}.pth\")\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n\n    model.eval()\n    val_loss = 0.0\n\n    with torch.no_grad():\n        for val_images, val_labels in val_loader:\n            val_images = val_images.to(device)\n            val_labels = val_labels.to(device)\n\n            val_outputs = model(val_images)  # Get raw logits from the model\n            probabilities = torch.sigmoid(val_outputs)  # Convert logits to probabilities if needed\n\n            val_loss += criterion(val_outputs, val_labels).item() * val_images.size(0)\n\n    val_loss /= len(val_loader.dataset)\n    print(f\"Validation Loss: {val_loss:.4f}\")\n\n\nprint(\"Training Complete\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:45:14.588916Z","iopub.execute_input":"2023-12-13T17:45:14.589878Z","iopub.status.idle":"2023-12-13T17:57:32.583256Z","shell.execute_reply.started":"2023-12-13T17:45:14.589835Z","shell.execute_reply":"2023-12-13T17:57:32.582115Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch [1/15], Loss: 0.0971\nValidation Loss: 0.0503\nEpoch [2/15], Loss: 0.0376\nValidation Loss: 0.1596\nEpoch [3/15], Loss: 0.0352\nValidation Loss: 0.0412\nEpoch [4/15], Loss: 0.0293\nValidation Loss: 0.0315\nEpoch [5/15], Loss: 0.0276\nValidation Loss: 0.0268\nEpoch [6/15], Loss: 0.0254\nValidation Loss: 0.0261\nEpoch [7/15], Loss: 0.0236\nValidation Loss: 0.0247\nEpoch [8/15], Loss: 0.0224\nValidation Loss: 0.0235\nEpoch [9/15], Loss: 0.0217\nValidation Loss: 0.0248\nEpoch [10/15], Loss: 0.0215\nValidation Loss: 0.0232\nEpoch [11/15], Loss: 0.0212\nValidation Loss: 0.0327\nEpoch [12/15], Loss: 0.0202\nValidation Loss: 0.0236\nEpoch [13/15], Loss: 0.0193\nValidation Loss: 0.0220\nEpoch [14/15], Loss: 0.0190\nValidation Loss: 0.0209\nEpoch [15/15], Loss: 0.0189\nValidation Loss: 0.0213\nTraining Complete\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### from IPython.display import FileLink\n\n![](http://)# Provide the path to the saved model file\nFileLink('trained_model3.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:57:50.793664Z","iopub.execute_input":"2023-12-04T15:57:50.794051Z","iopub.status.idle":"2023-12-04T15:57:50.801070Z","shell.execute_reply.started":"2023-12-04T15:57:50.794023Z","shell.execute_reply":"2023-12-04T15:57:50.800135Z"}}},{"cell_type":"code","source":"FileLink('14.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-13T17:59:43.855378Z","iopub.execute_input":"2023-12-13T17:59:43.856183Z","iopub.status.idle":"2023-12-13T17:59:43.890148Z","shell.execute_reply.started":"2023-12-13T17:59:43.856146Z","shell.execute_reply":"2023-12-13T17:59:43.888940Z"},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mFileLink\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m14.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'FileLink' is not defined"],"ename":"NameError","evalue":"name 'FileLink' is not defined","output_type":"error"}]},{"cell_type":"markdown","source":"##### from IPython.display import FileLink\n\n# Provide the path to the saved model file\nFileLink('trained_model3.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-04T15:57:50.793664Z","iopub.execute_input":"2023-12-04T15:57:50.794051Z","iopub.status.idle":"2023-12-04T15:57:50.801070Z","shell.execute_reply.started":"2023-12-04T15:57:50.794023Z","shell.execute_reply":"2023-12-04T15:57:50.800135Z"}}},{"cell_type":"code","source":"# Define the model architecture (same as during training)\nimport torch\nimport segmentation_models_pytorch as smp\n\n# Define device: Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load the pre-trained model\nmodel = smp.Unet(\n    encoder_name=\"mobilenet_v2\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n).to(device)\n\n\n\n# Load the saved model weights\nmodel.load_state_dict(torch.load('/kaggle/input/trained-model-pth/trained_model.pth'))\nprint(' ')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T12:08:49.581352Z","iopub.execute_input":"2023-12-04T12:08:49.581674Z","iopub.status.idle":"2023-12-04T12:08:56.462589Z","shell.execute_reply.started":"2023-12-04T12:08:49.581642Z","shell.execute_reply":"2023-12-04T12:08:56.461429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as transforms\nfrom PIL import Image\n\n\n\n# Load and preprocess test images\nimage1 = img_transform(Image.open('/kaggle/input/images/02610.jpg')).unsqueeze(0).to(device) \nimage2 = img_transform(Image.open('/kaggle/input/images/04950.jpg')).unsqueeze(0).to(device) \n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T13:04:11.510255Z","iopub.execute_input":"2023-12-04T13:04:11.511264Z","iopub.status.idle":"2023-12-04T13:04:11.564276Z","shell.execute_reply.started":"2023-12-04T13:04:11.511219Z","shell.execute_reply":"2023-12-04T13:04:11.563347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform inference on the test images\nwith torch.no_grad():\n    output1 = torch.sigmoid(model(image1))\n    output2 = model(image2)\n\n# Process the model's output as needed\nthreshold = 0.5\nprint(output1)\noutput1_binary = (output1 > threshold).float().cpu().numpy()\noutput2_binary = (output2 > threshold).float().cpu().numpy()\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T13:04:38.901780Z","iopub.execute_input":"2023-12-04T13:04:38.902194Z","iopub.status.idle":"2023-12-04T13:04:38.932034Z","shell.execute_reply.started":"2023-12-04T13:04:38.902157Z","shell.execute_reply":"2023-12-04T13:04:38.931122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Display the first test image and its corresponding model output\nplt.figure(figsize=(12, 6))\n\n# Original test image\nplt.subplot(1, 2, 1)\nplt.title(\"Test Image 1\")\nplt.imshow(image1.squeeze().cpu().permute(1, 2, 0))  # Convert tensor to a numpy array\n\n# Model's output (binary mask)\nplt.subplot(1, 2, 2)\nplt.title(\"Model Output 1\")\nplt.imshow(output1.squeeze().cpu())  \n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n\n# Load the dataset\ndataset = LaneDetectionDataset(images_npy='/kaggle/working/images.npy', labels_npy='/kaggle/working/labels.npy', \n                              img_transform=img_transform, label_transform=label_transform)\n\n# Create a DataLoader\n# For a single image, you can set batch_size to 1\nloader = DataLoader(dataset, batch_size=1, shuffle=False)\n\n# Process each image in the DataLoader\ncount=0\nfor img, label in loader:\n    count+=1\n    img = img.to(device)  # Move the image to the device (CPU or GPU)\n    with torch.no_grad():\n        output = model(img)  # Get the model's prediction\n    plt.subplot(1, 2, 1)\n    plt.imshow((output).squeeze().cpu())  # Convert tensor to a numpy array\n    plt.subplot(1, 2, 2)\n    plt.imshow((label).squeeze().cpu())  # Convert tensor to a numpy arr\n    if count==3:\n        break\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T13:05:22.484436Z","iopub.execute_input":"2023-12-04T13:05:22.484801Z","iopub.status.idle":"2023-12-04T13:05:23.170778Z","shell.execute_reply.started":"2023-12-04T13:05:22.484771Z","shell.execute_reply":"2023-12-04T13:05:23.169882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef test_dataset(dataset, num_samples=5):\n    # Create a DataLoader for testing with batch size 1\n    test_loader = DataLoader(dataset, batch_size=1, shuffle=True)\n    \n    # Iterate through the DataLoader and display a few examples\n    for i, (image, label) in enumerate(test_loader):\n        if i >= num_samples:\n            break\n        \n        # Convert tensor to numpy array and transpose the image to (H, W, C) format\n        image = image.squeeze().numpy().transpose(1, 2, 0)\n        label = label.squeeze().numpy()\n\n        # Display the image and label\n        plt.figure(figsize=(10, 5))\n        plt.subplot(1, 2, 1)\n        plt.imshow(image)\n        plt.title('Image')\n        plt.axis('off')\n        \n        plt.subplot(1, 2, 2)\n        plt.imshow(label, cmap='gray')\n        plt.title('Label')\n        plt.axis('off')\n        \n        plt.show()\n\n# Test the train_dataset\ntest_dataset(train_dataset, num_samples=5)\n\n# Test the val_dataset\ntest_dataset(val_dataset, num_samples=5)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T09:32:37.250380Z","iopub.execute_input":"2023-12-04T09:32:37.251265Z","iopub.status.idle":"2023-12-04T09:32:37.609115Z","shell.execute_reply.started":"2023-12-04T09:32:37.251217Z","shell.execute_reply":"2023-12-04T09:32:37.608003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation","metadata":{}},{"cell_type":"code","source":"    # Validation\n    model.eval()\n    with torch.no_grad():\n        val_loss = 0.0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n\n        val_loss /= len(val_loader.dataset)\n        print(f\"Validation Loss: {val_loss:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-12-04T01:08:15.475918Z","iopub.status.idle":"2023-12-04T01:08:15.476283Z","shell.execute_reply.started":"2023-12-04T01:08:15.476111Z","shell.execute_reply":"2023-12-04T01:08:15.476128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Downloading Dataset","metadata":{}},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:54:11.100697Z","iopub.execute_input":"2023-12-15T18:54:11.101026Z","iopub.status.idle":"2023-12-15T18:54:24.035098Z","shell.execute_reply.started":"2023-12-15T18:54:11.101000Z","shell.execute_reply":"2023-12-15T18:54:24.034094Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.2)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.7.22)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/u/0/uc?id=1I264WVBL3Dyp_4PTfEYkVIDkg_Yn5gJJ&export=download'  # Replace with your shareable link\noutput = 'labels.npy'  # Replace with your desired output filename and extension\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:54:26.505592Z","iopub.execute_input":"2023-12-15T18:54:26.506068Z","iopub.status.idle":"2023-12-15T18:54:29.969987Z","shell.execute_reply.started":"2023-12-15T18:54:26.506032Z","shell.execute_reply":"2023-12-15T18:54:29.969020Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/u/0/uc?id=1I264WVBL3Dyp_4PTfEYkVIDkg_Yn5gJJ&export=download\nFrom (redirected): https://drive.google.com/uc?id=1I264WVBL3Dyp_4PTfEYkVIDkg_Yn5gJJ&export=download&confirm=t&uuid=4a0f71cc-27b5-482b-897e-47233d83003b\nTo: /kaggle/working/labels.npy\n100%|██████████| 192M/192M [00:02<00:00, 81.8MB/s] \n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'labels.npy'"},"metadata":{}}]},{"cell_type":"code","source":"import gdown\n\nurl = 'https://drive.google.com/u/0/uc?id=1S23Ac0_hbOktV0rE2q0IkQWpQjUfkMTB&export=download'  # Replace with your shareable link\noutput = 'images.npy'  # Replace with your desired output filename and extension\ngdown.download(url, output, quiet=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:54:40.927024Z","iopub.execute_input":"2023-12-15T18:54:40.927630Z","iopub.status.idle":"2023-12-15T18:54:48.055393Z","shell.execute_reply.started":"2023-12-15T18:54:40.927594Z","shell.execute_reply":"2023-12-15T18:54:48.054404Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (uriginal): https://drive.google.com/u/0/uc?id=1S23Ac0_hbOktV0rE2q0IkQWpQjUfkMTB&export=download\nFrom (redirected): https://drive.google.com/uc?id=1S23Ac0_hbOktV0rE2q0IkQWpQjUfkMTB&export=download&confirm=t&uuid=df63532f-983a-431c-8994-7cc06a1aa144\nTo: /kaggle/working/images.npy\n100%|██████████| 576M/576M [00:06<00:00, 90.0MB/s] \n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'images.npy'"},"metadata":{}}]},{"cell_type":"code","source":"from PIL import Image\nfrom torchvision.transforms import ToTensor, Normalize, Compose\n\n\n\n# Load the image\nimage_path = '/kaggle/input/images/04950.jpg'\nplt.subplot(1, 2, 1)\nimage = Image.open(image_path)\nimage = img_transform(image).unsqueeze(0)  # Add a batch dimension\nplt.imshow(image.cpu()[0][0])\n\n# Move the image to the same device as the model\nplt.subplot(1, 2, 2)\nimage = image.to(device)\nmodel.eval()\nwith torch.no_grad():\n    output = model(image)\n    output = torch.sigmoid(output[0]).cpu()  # Apply sigmoid to convert output to probability\n    plt.imshow(output[0])\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T12:46:09.475907Z","iopub.status.idle":"2023-12-10T12:46:09.476236Z","shell.execute_reply.started":"2023-12-10T12:46:09.476075Z","shell.execute_reply":"2023-12-10T12:46:09.476091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    val_loss = 0.0\n\n    with torch.no_grad():\n        for val_images, val_labels in val_loader:\n            val_images = val_images.to(device)\n            val_labels = val_labels.to(device)\n\n            val_outputs = model(val_images)  # Get raw logits from the model\n            probabilities = torch.sigmoid(val_labels[0][0]).cpu()  # Convert logits to probabilities if needed\n            plt.imshow(val_images[0][0].cpu())\n\n    val_loss /= len(val_loader.dataset)\n    print(f\"Validation Loss: {val_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-04T14:26:26.364056Z","iopub.execute_input":"2023-12-04T14:26:26.365248Z","iopub.status.idle":"2023-12-04T14:26:31.908706Z","shell.execute_reply.started":"2023-12-04T14:26:26.365203Z","shell.execute_reply":"2023-12-04T14:26:31.907621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}